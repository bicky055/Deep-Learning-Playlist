# ðŸ“˜ Deep Learning Complete Guide (with Code and README)

## âœ… Prerequisites
- Python 3.7+
- Libraries: numpy, matplotlib, tensorflow or pytorch

## ðŸ“¦ Installation
```bash
pip install numpy matplotlib tensorflow
```

## ðŸ“‚ Project Structure
```
deep_learning_guide/
â”œâ”€â”€ 01_perceptron.py
â”œâ”€â”€ 02_activation_functions.py
â”œâ”€â”€ 03_forward_backward.py
â”œâ”€â”€ 04_gradient_descent.py
â”œâ”€â”€ 05_loss_functions.py
â”œâ”€â”€ 06_multilayer_network.py
â”œâ”€â”€ 07_chain_rule_backprop.py
â”œâ”€â”€ 08_vanishing_gradient.py
â””â”€â”€ README.md
```

---

# ðŸ“˜ README.md

## ðŸŽ¯ Goal
This guide helps beginners understand deep learning concepts from scratch with Python code examples.

---

## ðŸ“Œ Topics Covered

### 1. Perceptron (01_perceptron.py)
- Logic gates using a single-layer perceptron

### 2. Activation Functions (02_activation_functions.py)
- Sigmoid, ReLU, tanh, LeakyReLU
- Plots and code

### 3. Forward & Backward Propagation (03_forward_backward.py)
- Manual computation for 1-layer NN

### 4. Gradient Descent (04_gradient_descent.py)
- Intuition + code
- Visualization of cost minimization

### 5. Loss Functions (05_loss_functions.py)
- MSE, Binary Cross Entropy, Categorical Cross Entropy

### 6. Multilayered Neural Network (06_multilayer_network.py)
- MLP from scratch using numpy
- Then using TensorFlow (keras)

### 7. Chain Rule in Backprop (07_chain_rule_backprop.py)
- Full derivation of backprop with code

### 8. Vanishing Gradient (08_vanishing_gradient.py)
- Demonstrate problem with sigmoid
- Fix using ReLU

---

## ðŸ“Š Visualizations
- Activation function curves
- Training loss curves
- Weight updates

## ðŸš€ Next Steps
- CNNs, RNNs, Transformers
- Apply on real datasets (MNIST, CIFAR-10)

---

## ðŸ“§ Author
- Deep Learning Guide by ChatGPT & [Your Name]

---

Let me know which framework you prefer (TensorFlow or PyTorch), and Iâ€™ll generate the complete code for each file!
